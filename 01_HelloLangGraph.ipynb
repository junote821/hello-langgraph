{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6996a88e",
   "metadata": {},
   "source": [
    "### 설치된 라이브러리 버전 확인\n",
    "- **API 차이로 막히지 않도록 현재 설치 버전 명시**\n",
    "- **무엇**: `importlib.metadata.version()`로 `langgraph`, `openai`, `typing_extensions` 출력\n",
    "- **관찰**: 버전 문자열이 정상 출력되면 OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "def get_ver(pkg: str) -> str:\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return \"not installed\"\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"langgraph:\", get_ver(\"langgraph\"))\n",
    "print(\"openai:\", get_ver(\"openai\"))\n",
    "print(\"typing_extensions:\", get_ver(\"typing_extensions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a4859",
   "metadata": {},
   "source": [
    "### LM Studio 로컬 서버 연결\n",
    "- **OpenAI SDK 인터페이스 유지 + 로컬 호스팅 모델 사용**\n",
    "- **무엇**:\n",
    "  - `OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")`\n",
    "  - `client.models.list()`로 연결 확인\n",
    "  - `chat_local(prompt)` 보조 함수 정의\n",
    "- **관찰**: 모델 리스트 보이고 `chat_local(\"hi\")`가 응답\n",
    "- **이슈**: 연결 실패 시 LM Studio **Server 탭** 실행/포트 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09916cb9",
   "metadata": {},
   "source": [
    "#### LM Studio 모델 리스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# LM Studio 엔드포인트와 임의 API 키\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"lm-studio\"  # 임의 문자열 가능\n",
    ")\n",
    "\n",
    "# 간단한 헬스체크\n",
    "models = client.models.list()\n",
    "print(\"Models:\", [m.id for m in models.data])\n",
    "\n",
    "def chat_local(prompt: str, model: str = None, temperature: float = 0.2) -> str:\n",
    "    \"\"\"LM Studio 호환 Chat Completions 호출\"\"\"\n",
    "    model = model or (models.data[0].id if models.data else \"meta-llama-3.1-8b-instruct\")\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe1663",
   "metadata": {},
   "source": [
    "### OpenAI API 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 루트 폴더에 .env 파일을 만들고 아래처럼 키를 적어둡니다.\n",
    "#    OPENAI_API_KEY=sk-********************************\n",
    "# 2) 필요시 설치: uv add python-dotenv openai\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# .env 로딩\n",
    "_ = load_dotenv()  # 기본적으로 현재 작업 디렉터리의 .env 탐색\n",
    "\n",
    "# 환경변수에서 키 읽기 (dotenv가 주입)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"환경변수 OPENAI_API_KEY가 없습니다. 프로젝트 루트에 .env 파일을 만들고 \"\n",
    "        \"OPENAI_API_KEY=... 값을 넣은 뒤 다시 실행하세요.\"\n",
    "    )\n",
    "\n",
    "# OpenAI 기본 클라이언트 (공식 엔드포인트 사용, base_url 불필요)\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 사용할 모델 (필요시 변경)\n",
    "DEFAULT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def chat_local(prompt: str, model: str = None, temperature: float = 0.2) -> str:\n",
    "    \"\"\"\n",
    "    기존 노트북의 chat_local 함수를 OpenAI API 호출로 대체합니다.\n",
    "    다른 셀 코드는 수정 없이 그대로 사용 가능합니다.\n",
    "    \"\"\"\n",
    "    model = model or DEFAULT_MODEL\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return (resp.choices[0].message.content or \"\").strip()\n",
    "\n",
    "# 스모크 테스트\n",
    "print(chat_local(\"한 줄로 인사해줘\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd931698",
   "metadata": {},
   "source": [
    "### Hello, Graph\n",
    "- **LangGraph 모델(상태→노드→엣지) 파악**\n",
    "- **무엇**:\n",
    "  - 상태 `{\"input\",\"output\"}`\n",
    "  - `echo_node` 하나 + `START→echo→END`\n",
    "- **관찰**: `output`에 `Echo: ...` 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1(TypedDict):\n",
    "    input: str      # key나 값을 입력하는 것이 아닌 어떤 데이터가 들어갈것인지 전달\n",
    "    output: str\n",
    "\n",
    "g1 = StateGraph(S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드에서 사용할 에이전트\n",
    "def echo_node(state: S1) -> S1:\n",
    "    return {    # return 값은 state를 업데이트!\n",
    "        \"output\": f\"Echo: {state['input']}\"\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 생성\n",
    "g1.add_node(\"echo\", echo_node)\n",
    "\n",
    "# 엣지 연결 생성\n",
    "g1.add_edge(START, \"echo\")\n",
    "g1.add_edge(\"echo\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Compile -> 유효성 검사\n",
    "app1 = g1.compile()\n",
    "\n",
    "app1 # 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5429ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke로 값 입력 후 실행\n",
    "app1.invoke({\"input\": \"LangGraph 첫 그래프!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf0e5c",
   "metadata": {},
   "source": [
    "### LLM node 추가\n",
    "- **LLM 호출을 그래프 **노드로 캡슐화**하는 법 익히기**\n",
    "- **무엇**:\n",
    "  - 상태 `{\"question\",\"answer\"}`\n",
    "  - `llm_node` 내부에서 `chat_local()` 호출\n",
    "  - `START→llm→END`\n",
    "- **관찰**: `answer`에 한 줄 답 도착"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133709b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State 정의\n",
    "class S2(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "g2 = StateGraph(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 정의\n",
    "def echo_node(state: S2) -> S2:\n",
    "    print(\"Echo Node ->\", state)\n",
    "    return {    \n",
    "        \"question\": f\"Echo: {state['question']}\"\n",
    "    } \n",
    "\n",
    "def llm_node(state: S2) -> S2:\n",
    "    ans = chat_local(f\"한 문장으로 답해줘: {state['question']}\")\n",
    "    print(\"LLM Node ->\", state)\n",
    "    return {\"answer\": ans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 추가\n",
    "g2.add_node(\"echo_node\", echo_node)\n",
    "g2.add_node(\"llm_node\", llm_node)\n",
    "\n",
    "# 엣지 연결 추가\n",
    "g2.add_edge(START, \"llm_node\")\n",
    "g2.add_edge(\"llm_node\", \"echo_node\")\n",
    "g2.add_edge(\"echo_node\", END)\n",
    "app2 = g2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행!\n",
    "app2.invoke({\"question\": \"LangGraph는 무엇인가?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "app2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a160c",
   "metadata": {},
   "source": [
    "### Conditional Edge \n",
    "- **간단한 분기 생성**\n",
    "- **입력 유효성 검사 및 흐름 제어**\n",
    "- **무엇**:\n",
    "  - 상태 `{\"question\",\"result\"}`\n",
    "  - `route_fn`으로 빈 입력 시 종료, 아니면 처리\n",
    "  - `add_conditional_edges(\"validate\", route_fn, {\"empty\": END, \"ok\": \"answer\"})`\n",
    "- **관찰**: 빈 입력은 종료, 유효 입력은 답변 노드로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf581b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class S3(TypedDict):\n",
    "    question: str\n",
    "    result: str\n",
    "\n",
    "def validate(state: S3) -> S3:\n",
    "    q = (state.get(\"question\") or \"\").strip()\n",
    "    return {\"result\": \"빈 질문\"}\n",
    "\n",
    "def answer(state: S3) -> S3:\n",
    "    q = state[\"question\"]\n",
    "    a = chat_local(f\"간단히 답해줘: {q}\")\n",
    "    return {\"result\": a}\n",
    "\n",
    "def route_fn(state: S3) -> str:\n",
    "    if not (state.get(\"question\") or \"\").strip():\n",
    "        return \"empty\"\n",
    "    return \"ok\"\n",
    "\n",
    "g3 = StateGraph(S3)\n",
    "g3.add_node(\"validate\", validate)\n",
    "g3.add_node(\"answer\", answer)\n",
    "g3.add_edge(START, \"validate\")\n",
    "g3.add_conditional_edges(\"validate\", route_fn, {\"empty\": END, \"ok\": \"answer\"})\n",
    "g3.add_edge(\"answer\", END)\n",
    "app3 = g3.compile()\n",
    "\n",
    "print(app3.invoke({\"question\": \"\"}))\n",
    "print(app3.invoke({\"question\": \"Conditional Edge는 언제 쓰나?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6684277",
   "metadata": {},
   "source": [
    "### Reducer(상태 합치기)\n",
    "- **여러 노드 결과를 **한 키(리스트)**로 안전히 누적**\n",
    "- **무엇**:\n",
    "  - 상태에 `facts: Annotated[list[str], operator.add]`\n",
    "  - `fact_a`, `fact_b`가 각각 한 문장 생성 → 리스트 병합\n",
    "- **관찰**: `facts`에 2개 이상 항목이 합쳐져 반환\n",
    "- **이슈**: `reducer` 미지정 시 덮어쓰기 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "import operator\n",
    "\n",
    "class S4(TypedDict):\n",
    "    topic: str\n",
    "    facts: Annotated[list[str], operator.add]  # 리스트를 합치는 규칙\n",
    "\n",
    "def fact_a(state: S4) -> S4:\n",
    "    t = state[\"topic\"]\n",
    "    return {\"facts\": [chat_local(f\"{t}에 대해 핵심 사실 1가지를 1문장으로.\", temperature=0.1)]}\n",
    "\n",
    "def fact_b(state: S4) -> S4:\n",
    "    t = state[\"topic\"]\n",
    "    return {\"facts\": [chat_local(f\"{t}에 대해 추가 사실 1가지를 1문장으로.\", temperature=0.1)]}\n",
    "\n",
    "g4 = StateGraph(S4)\n",
    "g4.add_node(\"fact_a\", fact_a)\n",
    "g4.add_node(\"fact_b\", fact_b)\n",
    "g4.add_edge(START, \"fact_a\")\n",
    "g4.add_edge(\"fact_a\", \"fact_b\")\n",
    "g4.add_edge(\"fact_b\", END)\n",
    "app4 = g4.compile()\n",
    "\n",
    "app4.invoke({\"topic\": \"LangGraph\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06c558",
   "metadata": {},
   "source": [
    "### 체크포인트 & 스트리밍\n",
    "- **실행 추적/디버깅/재실행(thread)**\n",
    "- **무엇**:\n",
    "  - `MemorySaver` checkpointer\n",
    "  - 같은 `thread_id`로 `app.stream(..., stream_mode=\"values\")` 두 번 실행\n",
    "- **관찰**: 중간 상태가 흘러나오고, 재실행도 로그가 보임\n",
    "- **이슈**: `stream_mode=\"values\"`와 `thread_id` 누락 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# 이전 상태 재사용 가능한 간단 그래프\n",
    "class S5(TypedDict):\n",
    "    text: str\n",
    "    steps: Annotated[list[str], operator.add]\n",
    "\n",
    "def step1(state: S5) -> S5:\n",
    "    return {\"steps\": [f\"입력 길이: {len(state['text'])}\"]}\n",
    "\n",
    "def step2(state: S5) -> S5:\n",
    "    s = chat_local(f\"요약: {state['text']}\")\n",
    "    return {\"steps\": [f\"요약완료({len(s)}자)\"]}\n",
    "\n",
    "g5 = StateGraph(S5)\n",
    "g5.add_node(\"step1\", step1)\n",
    "g5.add_node(\"step2\", step2)\n",
    "g5.add_edge(START, \"step1\")\n",
    "g5.add_edge(\"step1\", \"step2\")\n",
    "g5.add_edge(\"step2\", END)\n",
    "app5 = g5.compile(checkpointer=checkpointer)\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"demo-1\"}}\n",
    "\n",
    "print(\"== 1차 실행 ==\")\n",
    "for update in app5.stream({\"text\": \"LangGraph는 상태+노드+엣지로 구성된 워크플로우 엔진.\"}, thread, stream_mode=\"values\"):\n",
    "    print(update)\n",
    "\n",
    "print(\"\\n== 2차 실행(같은 thread_id) ==\")\n",
    "for update in app5.stream({\"text\": \"같은 스레드에서 두 번째 실행\"}, thread, stream_mode=\"values\"):\n",
    "    print(update)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c609b",
   "metadata": {},
   "source": [
    "### Send / Command\n",
    "- 동적 fan-out\n",
    "- 한 개 입력에 포함된 여러 sub-question을 계획 -> 병렬 답변 -> 모으기 흐름으로 처리\n",
    "- 하나의 입력을 **여러 하위 작업**(질문들)으로 병렬 처리\n",
    "- **무엇**:\n",
    "  - 상태:  \n",
    "    - `questions: Annotated[list[str], operator.add]`  \n",
    "    - `answers:   Annotated[list[str], operator.add]`\n",
    "  - `plan` 노드: raw 텍스트를 `?` 기준으로 분리해 `questions`에 저장\n",
    "  - **핵심**: `add_conditional_edges(\"plan\", fanout)`에서 `fanout`이  \n",
    "    `return [Send(\"qa\", {\"question\": q}) for q in state[\"questions\"]]` 반환\n",
    "  - `qa` 노드: `state[\"question\"]`를 읽고 답 생성 → `answers`에 1개씩 추가\n",
    "  - 엣지: `START→plan`, `qa→join`, `join→END`\n",
    "- **관찰**:\n",
    "  - 스트리밍: `{'questions': [...]}` 후 `{'answers': ['Q: ... | A: ...']}`가 **여러 번** 출력\n",
    "  - 최종 상태에서 모든 Q/A가 `answers`에 누적\n",
    "- **이슈**:\n",
    "  - `answers`가 비면  \n",
    "    ① 리듀서 누락(반드시 `Annotated[..., operator.add]`)  \n",
    "    ② 팬아웃 미실행(조건 엣지/`Send` 반환 확인)  \n",
    "    ③ `qa`에서 `question` 접근 방식 확인(`state[\"question\"]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc090a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "import operator\n",
    "\n",
    "# 1) 상태: 리스트 병합 규칙 꼭 지정\n",
    "class S(TypedDict):\n",
    "    raw: str\n",
    "    questions: Annotated[list[str], operator.add]\n",
    "    answers:   Annotated[list[str], operator.add]\n",
    "\n",
    "# 2) plan: 질문 리스트만 상태에 기록\n",
    "def plan(state: S):\n",
    "    qs = [p.strip()+\"?\" for p in state[\"raw\"].split(\"?\") if p.strip()]\n",
    "    return {\"questions\": qs}\n",
    "\n",
    "# 3) fanout(조건 엣지 함수): qa로 Send 목록 반환  ← 핵심!\n",
    "def fanout(state: S):\n",
    "    return [Send(\"qa\", {\"question\": q}) for q in state[\"questions\"]]\n",
    "\n",
    "# 4) qa: Send로 넘어온 입력(arg)에 'question'이 담겨옴\n",
    "def qa(state: S) -> S:\n",
    "    q = state.get(\"question\", \"\")\n",
    "    a = chat_local(f\"아주 짧게 대답해줘: {q}\", temperature=0.1) or \"\"\n",
    "    return {\"answers\": [f\"Q: {q} | A: {a.strip()}\"]}\n",
    "\n",
    "# 5) join: 마무리(패스스루)\n",
    "def join(state: S) -> S:\n",
    "    return {}\n",
    "\n",
    "# 6) 그래프 구성\n",
    "g = StateGraph(S)\n",
    "g.add_node(\"plan\", plan)\n",
    "g.add_node(\"qa\", qa)\n",
    "g.add_node(\"join\", join)\n",
    "\n",
    "g.add_edge(START, \"plan\")\n",
    "# plan 다음 흐름을 '조건 엣지'로 정의 → qa가 질문 수만큼 실행됨\n",
    "g.add_conditional_edges(\"plan\", fanout)\n",
    "# qa 실행이 끝난 뒤 join으로 수집\n",
    "g.add_edge(\"qa\", \"join\")\n",
    "g.add_edge(\"join\", END)\n",
    "\n",
    "app = g.compile()\n",
    "\n",
    "# 7) 실행\n",
    "out = app.invoke({\"raw\": \"LangGraph는 무엇인가? Conditional Edge는 언제 쓰나? Reducer는 왜 필요한가?\"})\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81976ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f36bd23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "팬아웃(fan-out)은 **하나의 단계(노드)에서 여러 개의 하위 작업을 동시에(또는 여러 번) 흩뿌려 실행**하는 패턴  \n",
    "“**하나 들어오면 → N개로 나눠서 → 각각 돌리고 → 다시 모은다**”\n",
    "\n",
    "---\n",
    "\n",
    "## 사용 이유\n",
    "\n",
    "* **평행 작업**: 여러 질문/문서/URL을 **동시에** 처리하여 속도 상승\n",
    "* **분리 정복**: 큰 문제를 **작은 하위 문제**들로 나눠 고품질 답변 획득\n",
    "* **구조적 안전성**: 각 하위 작업을 독립 노드로 캡슐화(실패, 재시도, 로그 추적 쉬움)\n",
    "\n",
    "---\n",
    "\n",
    "## LangGraph에서 사용 방법\n",
    "\n",
    "1. **fan-out(흩뿌리기)**\n",
    "\n",
    "   * `Conditional Edge` 함수에서 `Send`들의 **리스트**를 반환\n",
    "     → 런타임이 `qa` 노드를 **질문 수만큼** 실행\n",
    "2. **fan-in(모으기 / join)**\n",
    "\n",
    "   * 각 `qa`가 상태에 결과를 적고(예: `answers`),\n",
    "   * **리듀서**(`Annotated[list[str], operator.add]`) 규칙으로 자동 병합\n",
    "   * 모두 끝나면 `join` 노드로 흐름이 이어짐\n",
    "\n",
    "\n",
    "### **Flow**\n",
    "\n",
    "```\n",
    "           ┌───────────┐\n",
    "input ───▶ │  plan     │─── fan-out ──┐\n",
    "           └───────────┘              │\n",
    "                 │                    │\n",
    "        [Send(\"qa\", q1), ...]         │\n",
    "                 │                    ▼\n",
    "           ┌───────────┐       ┌───────────┐\n",
    "           │   qa(q1)  │  ...  │   qa(qN)  │\n",
    "           └───────────┘       └───────────┘\n",
    "                 \\______________________/ \n",
    "                          │  fan-in (리듀서로 병합)\n",
    "                          ▼\n",
    "                    ┌───────────┐\n",
    "                    │   join    │\n",
    "                    └───────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 활용 방안\n",
    "\n",
    "* **여러 질문/프롬프트**를 한 번에 답할 때\n",
    "* **문서/URL 배치 처리**(요약, 추출, 분류)\n",
    "* **검색 결과 다건 스코어링** 후 상위 N개 선별\n",
    "\n",
    "---\n",
    "\n",
    "## 실전 팁\n",
    "\n",
    "* **`reducer` 필수**: 리스트/딕셔너리로 결과를 모을 땐\n",
    "  `Annotated[list[T], operator.add]`처럼 병합 규칙을 반드시 지정\n",
    "* **입력 크기 제어**: 하위 작업이 너무 많으면 rate limit에 걸릴 수 있어 **batch 크기**나 **동시성**을 제한\n",
    "* **결정성**: 병렬 실행 순서는 미보장일 수 있어 **정렬 키**(예: 원래 인덱스) 보관 권장\n",
    "* **에러 처리**: 각 `qa`에서 예외를 잡아 **에러 메시지도 결과로** 남기면 디버깅 용이\n",
    "\n",
    "---\n",
    "\n",
    "## 한 줄 정의\n",
    "\n",
    "> **Fan-out/Fan-in**: 하나의 입력을 여러 하위 작업으로 **동시에 실행**하고, **reducer 규칙**으로 결과를 **합쳐** 다음 단계로 넘기는 그래프 패턴\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
